{
  "architecture_hash": "09b34d0f70133123443b78d7d4007299",
  "model_type": "DQNetwork",
  "architecture_summary": "DQNetwork(\n  (fc1): Linear(in_features=6, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=128, bias=True)\n  (fc4): Linear(in_features=128, out_features=210, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.2, inplace=False)\n  (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)",
  "hyperparameters": {
    "memory_size": 10000,
    "batch_size": 64,
    "gamma": 0.99,
    "epsilon": 1.0,
    "epsilon_min": 0.1,
    "epsilon_decay": 0.998,
    "learning_rate": 0.001,
    "state_size": 6,
    "action_size": 210
  },
  "metrics": {
    "losses": [
      325994432.0,
      265835392.0,
      212789376.0,
      188810816.0,
      174760512.0,
      156373744.0,
      132211424.0,
      135633216.0,
      158690768.0,
      185035520.0,
      242155424.0,
      204574448.0,
      168483184.0,
      230572064.0,
      225454224.0,
      193648176.0,
      177179248.0,
      221887504.0,
      216715232.0,
      201136432.0,
      215845920.0
    ],
    "rewards": [
      16200.0,
      15873.573121743404,
      -418.82806240724676,
      -11070.624064697588,
      -36149.13164800479,
      -51530.355017209615,
      -79227.44684378219,
      -90274.78788416983,
      -126906.83113025877,
      -144339.66921212903,
      -166924.1871116172,
      -173563.51125767603,
      -191563.51125767603,
      -208193.51125767603,
      -224053.51125767603,
      -239493.51125767603,
      -254733.51125767603,
      -269863.51125767606,
      -284923.51125767606,
      -299953.51125767606,
      -314963.51125767606,
      -329963.51125767606,
      -344963.51125767606,
      -359963.51125767606,
      -374963.51125767606,
      -389963.51125767606,
      -404963.51125767606,
      -419963.51125767606,
      -434963.51125767606,
      -449963.51125767606,
      -464963.51125767606,
      -479963.51125767606,
      -486722.8354037349,
      -505002.8354037349,
      -521842.8354037349,
      -537852.8354037348,
      -553392.8354037348,
      -568682.8354037348,
      -583842.8354037348,
      -598932.8354037348,
      -613982.8354037348,
      -629002.8354037348,
      -644012.8354037348,
      -659012.8354037348,
      -674012.8354037348,
      -689012.8354037348,
      -704012.8354037348,
      -719012.8354037348,
      -734012.8354037348,
      -749012.8354037348,
      -764012.8354037348,
      -779012.8354037348,
      -794012.8354037348,
      -800682.1595497936,
      -818782.1595497936,
      -826526.8050620748,
      -842506.8050620748,
      -858026.8050620748,
      -873296.8050620748,
      -888446.8050620748,
      -903526.8050620748,
      -918566.8050620748,
      -933586.8050620748,
      -948596.8050620748,
      -968117.5353777938,
      -975367.5353777938,
      -1004287.6679784798,
      -1034022.8228258791,
      -1032896.5136044535,
      -1046182.7289560427,
      -1066179.0383479046,
      -1102066.379074656,
      -1140549.022348454,
      -1181335.4689658694,
      -1174486.4482945018,
      -1183073.9724910683,
      -1196428.546237771,
      -1214351.6352290346,
      -1235329.9601661887,
      -1250482.0088330654,
      -1271010.7797519579,
      -1294228.2271026368,
      -1319862.9349067295,
      -1343873.3673086956
    ],
    "epsilons": [
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05,
      0.05
    ]
  }
}